# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
This dataset contains data about a bank marketing campaign. We need to to predict whether a given client would subscribe to a term deposit or not. The dataset contained information about the last call that was made to the prospective client about the current campaign and the information about the client's credit history and demographic data

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
Logistic regression model was successful with 90.78% accuracy whereas AutoMl model produced 94.98% accuracy.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
Dataset was loaded with the provided URL, which was tabular dataset type. Cleaning the data was done proceeded by data spliting into train data and tets data.
Logistic regression was chosen as prediction model. Compute infra was created, hyperparameter tuning was done using Random paramater sampling and Bandit early termination policy. 

**What are the benefits of the parameter sampler you chose?**
Random sampling supports discrete and continuous hyperparameters. It supports early termination of low-performance runs. In random sampling, hyperparameter values are randomly selected from the defined search space. The regularization hyperparameter (C) is set to ensure that our model does not overfit the data by penalizing addition of features. The max_iter (maximum iteration) hyperparameter controls the number of iterations to be done before we select our final model.
loguniform(0.5,6) for C and choice(50,100,200,500) for max_iter is chosen.

**What are the benefits of the early stopping policy you chose?**
Bandit policy is based on slack factor/slack amount and evaluation interval. Bandit terminates runs where the primary metric is not within the specified slack factor/slack amount compared to the best performing run. Evaluation_interval = 2 and slack_factor = 0.1 are chosen for the Bandit policy.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
Training data was created using provided tabular dataset. AutoML pipeline is similar to Scikit-learn pipeline in terms of data pereparation and feature engineering. 

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
HYPERDRIVE PIPELINE: Best Run Id:  HD_eb00da3a-f61d-421c-b187-d86b2bae7110_1
                     Accuracy:  0.9078907435508345
                     Parameters: '--C', '39.30325278873106', '--max_iter', '500'
                     
AUTOML PIPELINE:     ITERATION   PIPELINE                                       DURATION      METRIC      BEST
                            44   VotingEnsemble                                 0:01:03       0.9498    0.9498
                            45   StackEnsemble                                  0:01:24       0.9497    0.9498
                     Stopping criteria reached at iteration 46. Ending experiment.
AutoML performed better interms of accuracy when compared to Hyperdrive pipeline. AutoML ran for 46 iterations to produce best metric of 94.97% accuracy and Hyperdrive resulted in 90.78% accuracy with C = 39.303 and 500 maximum iterations. 

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
By choosing various primary metrics and classifications methods, we can imrpvise the model interms of better accuracy and least error. Effects of number of clusters can also be studied to learn about faster learning rate in details. 

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**

